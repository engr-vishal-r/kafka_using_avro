# Kafka Using Avro (MySQL â†’ Kafka â†’ Avro Serialization)

This project demonstrates a simple end-to-end data pipeline that fetches data from a MySQL database, serializes it using **Apache Avro**, and publishes it to **Apache Kafka**. The data is then consumed from Kafka and deserialized back into readable form.

---

## ðŸ“Œ Key Components

- **MySQL** â€“ Source of customer data
- **Apache Kafka** â€“ Message broker for streaming data
- **Apache Avro** â€“ Serialization format for compact, fast data exchange
- **Python (Confluent Kafka client)** â€“ Used for producer/consumer
- **customer.avsc** â€“ Avro schema file used for serialization/deserialization

---

## ðŸ”„ Pipeline Flow

```text
MySQL â†’ Python Producer â†’ Avro Serialization â†’ Kafka Topic â†’ Python Consumer â†’ Avro Deserialization